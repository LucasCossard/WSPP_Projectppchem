{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhbq75iPPaamW1Dlh131Ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nohalyan/Projetppchem/blob/Lucas1/Notebook_WSP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Water Solubility Predisction\n",
        "\n"
      ],
      "metadata": {
        "id": "9we0xsQKCIis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Import Relevant Modules and Libraries\n",
        "\n",
        "Let's first start by importing relevant modules and libraries needed for this project.\n"
      ],
      "metadata": {
        "id": "9VBM8XdnDHfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all libraries\n",
        "!pip install pathlib numpy pandas rdkit matplotlib scikit-learn lightgbm lazypredict tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFhpnlDlEGpP",
        "outputId": "902a3788-1a55-4374-eae2-2b0b6248db01"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2023.9.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: lazypredict in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (2.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "xDEhgWFsCC0T"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# lazypredict helps to train 42 ML models with a single line of code ans find the best ML models\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Let's get the Solubility Data\n",
        "\n",
        "First, we will get solubility data from gashawmg (source: https://github.com/gashawmg) and perform exploratory data analysis"
      ],
      "metadata": {
        "id": "_HeTUCurHCnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Nohalyan/Projetppchem/main/Data_Solubility.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiN0eigVHNgz",
        "outputId": "bd9f6468-7d3f-42c4-d5ed-ff6d62ed0249"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-23 07:59:54--  https://raw.githubusercontent.com/Nohalyan/Projetppchem/main/Data_Solubility.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 987356 (964K) [text/plain]\n",
            "Saving to: ‘Data_Solubility.csv’\n",
            "\n",
            "Data_Solubility.csv 100%[===================>] 964.21K  5.44MB/s    in 0.2s    \n",
            "\n",
            "2024-04-23 07:59:55 (5.44 MB/s) - ‘Data_Solubility.csv’ saved [987356/987356]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's open the file"
      ],
      "metadata": {
        "id": "MNh8CNiSb3c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Path object for the current directory, in our case /content/\n",
        "current_directory = Path.cwd()\n",
        "print(\"Current Directory:\", current_directory.resolve())\n",
        "\n",
        "file_path = current_directory / \"Data_Solubility.csv\"\n",
        "\n",
        "# Reading the contents of the file and check that the file exists\n",
        "if file_path.exists():\n",
        "    with file_path.open(\"r\") as file:\n",
        "        content = file.read()\n",
        "#       print(content)\n",
        "else:\n",
        "    print(\"The file does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYPnESo9bPPp",
        "outputId": "b0ed5e17-3bdd-4902-f0ca-052a060968ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file use semicicolon as delimiter, so let's open the file and use semicicolon as delimiter:"
      ],
      "metadata": {
        "id": "HhmAA3fHh1kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open a file containing descriptors and yield\n",
        "data_solubility = pd.read_csv(\"/content/Data_Solubility.csv\", delimiter=';')"
      ],
      "metadata": {
        "id": "3cJRK4pwWNwn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the data see if it is what we want"
      ],
      "metadata": {
        "id": "gEJ2RcUqhktQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_solubility.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2egFBYgjf17S",
        "outputId": "e7f23aaf-54c9-418e-cab8-97539ee025f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9943, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_solubility.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V9zwa1_mhblV",
        "outputId": "18509aa7-9dc0-48f6-ddf9-721b653d95fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Compound ID                     InChIKey  \\\n",
              "0       C1711  ACTIUHUUMQJHFO-UPTCCGCDSA-N   \n",
              "1       C1712  CQISYTXUORWJSX-UHFFFAOYSA-N   \n",
              "2       C1713  UXPYIAWFQKSHNV-UHFFFAOYSA-N   \n",
              "3       C1714  BDIWFCKBPZPBQT-UHFFFAOYSA-N   \n",
              "4       C1715  RNPXCFINMKSQPQ-UHFFFAOYSA-N   \n",
              "\n",
              "                                              SMILES   logS  logP     MW  \n",
              "0  COC1=C(OC)C(=O)C(=C(C1=O)C/C=C(/CC/C=C(/CC/C=C... -18.22 17.85 863.34  \n",
              "1  CCCCCCCCCCCCCCCCCC(=O)Nc1ccc(cc1)NC(=O)CCCCCCC... -17.47 14.23 641.07  \n",
              "2     CCCCCCCCCCCCCCCC(=O)OCCCCOC(=O)CCCCCCCCCCCCCCC -16.26 11.82 566.94  \n",
              "3          CCCC[Sn](S[Sn](CCCC)(CCCC)CCCC)(CCCC)CCCC -15.68 10.41 612.15  \n",
              "4         CCCCCCCCCCCCCCCCOP(=O)(OCCCCCCCCCCCCCCCC)O -15.21 12.08 546.85  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-980a6d6f-a090-41b7-8e4a-3fc6e8a019b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Compound ID</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>logS</th>\n",
              "      <th>logP</th>\n",
              "      <th>MW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C1711</td>\n",
              "      <td>ACTIUHUUMQJHFO-UPTCCGCDSA-N</td>\n",
              "      <td>COC1=C(OC)C(=O)C(=C(C1=O)C/C=C(/CC/C=C(/CC/C=C...</td>\n",
              "      <td>-18.22</td>\n",
              "      <td>17.85</td>\n",
              "      <td>863.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C1712</td>\n",
              "      <td>CQISYTXUORWJSX-UHFFFAOYSA-N</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCC(=O)Nc1ccc(cc1)NC(=O)CCCCCCC...</td>\n",
              "      <td>-17.47</td>\n",
              "      <td>14.23</td>\n",
              "      <td>641.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C1713</td>\n",
              "      <td>UXPYIAWFQKSHNV-UHFFFAOYSA-N</td>\n",
              "      <td>CCCCCCCCCCCCCCCC(=O)OCCCCOC(=O)CCCCCCCCCCCCCCC</td>\n",
              "      <td>-16.26</td>\n",
              "      <td>11.82</td>\n",
              "      <td>566.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C1714</td>\n",
              "      <td>BDIWFCKBPZPBQT-UHFFFAOYSA-N</td>\n",
              "      <td>CCCC[Sn](S[Sn](CCCC)(CCCC)CCCC)(CCCC)CCCC</td>\n",
              "      <td>-15.68</td>\n",
              "      <td>10.41</td>\n",
              "      <td>612.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C1715</td>\n",
              "      <td>RNPXCFINMKSQPQ-UHFFFAOYSA-N</td>\n",
              "      <td>CCCCCCCCCCCCCCCCOP(=O)(OCCCCCCCCCCCCCCCC)O</td>\n",
              "      <td>-15.21</td>\n",
              "      <td>12.08</td>\n",
              "      <td>546.85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-980a6d6f-a090-41b7-8e4a-3fc6e8a019b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-980a6d6f-a090-41b7-8e4a-3fc6e8a019b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-980a6d6f-a090-41b7-8e4a-3fc6e8a019b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9c2b770-19cb-4d6a-9aea-617efdccdddf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c2b770-19cb-4d6a-9aea-617efdccdddf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9c2b770-19cb-4d6a-9aea-617efdccdddf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_solubility",
              "summary": "{\n  \"name\": \"data_solubility\",\n  \"rows\": 9943,\n  \"fields\": [\n    {\n      \"column\": \"Compound ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9943,\n        \"samples\": [\n          \"C8926\",\n          \"C7048\",\n          \"C1341\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"InChIKey\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9941,\n        \"samples\": [\n          \"PXSOHRWMIRDKMP-UHFFFAOYSA-N\",\n          \"BOQSSGDQNWEFSX-UHFFFAOYSA-N\",\n          \"KBLOTQMFQLJJPR-UHFFFAOYSA-N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9943,\n        \"samples\": [\n          \"[O-][N+](=O)c1nccn1CCO\",\n          \"CN([C@H]1C(=O)C(=C([C@@]2([C@H]1C[C@H]1C(=C(O)c3c([C@@]1(C)O)cccc3O)C2=O)O)O)C(=O)N)C\",\n          \"OC(=O)c1cc(O)c(c(c1)O)O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.207156608482586,\n        \"min\": -18.21769274,\n        \"max\": 1.7,\n        \"num_unique_values\": 8388,\n        \"samples\": [\n          -2.385100896,\n          -5.227098562,\n          -2.995649881\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3033718173377005,\n        \"min\": -10.9338,\n        \"max\": 20.8546,\n        \"num_unique_values\": 8184,\n        \"samples\": [\n          1.5304,\n          1.2199,\n          2.9747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138.78315475567555,\n        \"min\": 16.0425,\n        \"max\": 1583.57,\n        \"num_unique_values\": 6425,\n        \"samples\": [\n          441.157,\n          162.142,\n          418.294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks nice to me!"
      ],
      "metadata": {
        "id": "OFo14mE9hvdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2 Data Cleaning\n",
        "## 2.2.1 Remove NaN or null values\n",
        "\n",
        "We wil start by removing non-numerical values and valeurs that are null:"
      ],
      "metadata": {
        "id": "rsPHJbgfinOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_solubility.SMILES.isnull().sum()\n",
        "data_solubility.dropna(inplace=True)\n",
        "data_solubility.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wnyNXZkicm3",
        "outputId": "de3c6b10-b28d-45ea-c9aa-1e993df2f6e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9943, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the shape is still the same, the data has already been cleaned of non-numerical and null values.\n",
        "##2.2.2 Remove outliers\n",
        "\n",
        "Then, we will remove outliers from the data. Using a boxplot, we can easely visualize outliers:\n"
      ],
      "metadata": {
        "id": "QC27TZqri8CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sn.set_theme()\n",
        "sn.displot(data=data_solubility, x=\"logS\", binwidth=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "kuD5t60TnrX5",
        "outputId": "364fe811-0c02-453c-eb49-5488a8bd1650"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7afda72df670>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's filter compounds that follow as close as normal distribution, let's say between -7.5 and 1.7:\n"
      ],
      "metadata": {
        "id": "MSFjaKMyqCV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_solubility = data_solubility[data_solubility.logS.apply(lambda x: x > -7.5 and x < 1.7)]"
      ],
      "metadata": {
        "id": "Ht-zgHIvqIJ6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's generate an histogram to see the new data:"
      ],
      "metadata": {
        "id": "QHgDSAQ8rWZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sn.displot(data=new_data_solubility, x='logS', binwidth=1,kde=True)\n",
        "new_data_solubility.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "9wjGJ5AGrW6B",
        "outputId": "e9d551ee-5616-4d32-cd28-fd12133ca055"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9648, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.3 Remove Duplicates\n",
        "\n",
        "Then remove duplicate by generating canonical SMILES:"
      ],
      "metadata": {
        "id": "lDjkwQEwlcMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a canonical SMILES function\n",
        "def canonical_SMILES(smiles):\n",
        "    canon_smls = [Chem.CanonSmiles(smls) for smls in smiles]\n",
        "    return canon_smls"
      ],
      "metadata": {
        "id": "KydIsfXejaJu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate canonical Smiles using the function\n",
        "canon_smiles = canonical_SMILES(new_data_solubility.SMILES)\n",
        "\n",
        "# Replace SMILES column with canonical SMILES\n",
        "new_data_solubility[\"SMILES\"] = canon_smiles\n",
        "\n",
        "# Create a list for duplicate smiles\n",
        "duplicate_smiles = new_data_solubility[new_data_solubility['SMILES'].duplicated()]['SMILES'].values\n",
        "len(duplicate_smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MDLZcMzjWtP",
        "outputId": "2057f377-e186-44e6-f2eb-fc70fa291c3a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, their are 6 duplicates, so we have to filter them and we can also sort them for better reading:"
      ],
      "metadata": {
        "id": "I7qNi08VkYMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_solubility[new_data_solubility['SMILES'].isin(duplicate_smiles)].sort_values(by=['SMILES'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "P73Yy1K7kXzV",
        "outputId": "f2df23c1-41e1-449f-9e05-f9062f067ea4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Compound ID                      InChIKey  \\\n",
              "5683       C1698   WUBBRNOQWQTFEX-UHFFFAOYSA-N   \n",
              "5836        C943   BZKPWHYZMXOIDC-UHFFFAOYSA-N   \n",
              "7282       C7745   VWPOSFSPZNDTMJ-UCWKZMIHSA-N   \n",
              "8063       C1707   IWVCMVBTMGNXQD-PXOLEDIWSA-N   \n",
              "1345        C199   WKRLQDKEXYKHJB-HFTRVMKXSA-N   \n",
              "1347       C1673  WKRLQDKEXYKHJB-HFTRVMKXSA-N    \n",
              "5152       C1696   QZUDBNBUXVUHMW-UHFFFAOYSA-N   \n",
              "5319        C843   JLKIGFTWXXRPMT-UHFFFAOYSA-N   \n",
              "3918        C604   NXFQHRVNIOXGAQ-YCRREMRBSA-N   \n",
              "4159       C1690   NXFQHRVNIOXGAQ-OQFOIZHKSA-N   \n",
              "9020       C1565   CPNGPNLZQNNVQM-UHFFFAOYSA-N   \n",
              "9021       C1709   RKUNBYITZUJHSG-SPUOUPEWSA-N   \n",
              "\n",
              "                                              SMILES  logS  logP     MW  \n",
              "5683                      CC(=O)Nc1nnc(S(N)(=O)=O)s1 -2.44  1.00 222.25  \n",
              "5836                      CC(=O)Nc1nnc(S(N)(=O)=O)s1 -2.36  1.00 222.25  \n",
              "7282    CC(C)(C)NCC(O)COc1cccc2c1C[C@H](O)[C@H](O)C2 -1.57  1.03 309.40  \n",
              "8063    CC(C)(C)NCC(O)COc1cccc2c1C[C@H](O)[C@H](O)C2 -1.01  1.03 309.40  \n",
              "1345  C[C@]12CC[C@H]3C(=CCc4cc(O)ccc43)[C@@H]1CCC2=O -5.28  3.74 268.35  \n",
              "1347  C[C@]12CC[C@H]3C(=CCc4cc(O)ccc43)[C@@H]1CCC2=O -5.28  3.74 268.35  \n",
              "5152                 Cc1cc(NS(=O)(=O)c2ccc(N)cc2)no1 -2.70  3.10 253.28  \n",
              "5319                 Cc1cc(NS(=O)(=O)c2ccc(N)cc2)no1 -2.62  3.10 253.28  \n",
              "3918       O=C1CN(/N=C/c2ccc([N+](=O)[O-])o2)C(=O)N1 -3.38  0.86 238.16  \n",
              "4159       O=C1CN(/N=C/c2ccc([N+](=O)[O-])o2)C(=O)N1 -3.24  0.86 238.16  \n",
              "9020                                  c1cnc2ncncc2n1  0.02  0.42 132.12  \n",
              "9021                                  c1cnc2ncncc2n1  0.02  0.42 132.12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7eb9938-92cc-46dd-9ce0-5a30140b5caf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Compound ID</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>logS</th>\n",
              "      <th>logP</th>\n",
              "      <th>MW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5683</th>\n",
              "      <td>C1698</td>\n",
              "      <td>WUBBRNOQWQTFEX-UHFFFAOYSA-N</td>\n",
              "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
              "      <td>-2.44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>222.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5836</th>\n",
              "      <td>C943</td>\n",
              "      <td>BZKPWHYZMXOIDC-UHFFFAOYSA-N</td>\n",
              "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
              "      <td>-2.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>222.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7282</th>\n",
              "      <td>C7745</td>\n",
              "      <td>VWPOSFSPZNDTMJ-UCWKZMIHSA-N</td>\n",
              "      <td>CC(C)(C)NCC(O)COc1cccc2c1C[C@H](O)[C@H](O)C2</td>\n",
              "      <td>-1.57</td>\n",
              "      <td>1.03</td>\n",
              "      <td>309.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8063</th>\n",
              "      <td>C1707</td>\n",
              "      <td>IWVCMVBTMGNXQD-PXOLEDIWSA-N</td>\n",
              "      <td>CC(C)(C)NCC(O)COc1cccc2c1C[C@H](O)[C@H](O)C2</td>\n",
              "      <td>-1.01</td>\n",
              "      <td>1.03</td>\n",
              "      <td>309.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>C199</td>\n",
              "      <td>WKRLQDKEXYKHJB-HFTRVMKXSA-N</td>\n",
              "      <td>C[C@]12CC[C@H]3C(=CCc4cc(O)ccc43)[C@@H]1CCC2=O</td>\n",
              "      <td>-5.28</td>\n",
              "      <td>3.74</td>\n",
              "      <td>268.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>C1673</td>\n",
              "      <td>WKRLQDKEXYKHJB-HFTRVMKXSA-N</td>\n",
              "      <td>C[C@]12CC[C@H]3C(=CCc4cc(O)ccc43)[C@@H]1CCC2=O</td>\n",
              "      <td>-5.28</td>\n",
              "      <td>3.74</td>\n",
              "      <td>268.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5152</th>\n",
              "      <td>C1696</td>\n",
              "      <td>QZUDBNBUXVUHMW-UHFFFAOYSA-N</td>\n",
              "      <td>Cc1cc(NS(=O)(=O)c2ccc(N)cc2)no1</td>\n",
              "      <td>-2.70</td>\n",
              "      <td>3.10</td>\n",
              "      <td>253.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5319</th>\n",
              "      <td>C843</td>\n",
              "      <td>JLKIGFTWXXRPMT-UHFFFAOYSA-N</td>\n",
              "      <td>Cc1cc(NS(=O)(=O)c2ccc(N)cc2)no1</td>\n",
              "      <td>-2.62</td>\n",
              "      <td>3.10</td>\n",
              "      <td>253.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3918</th>\n",
              "      <td>C604</td>\n",
              "      <td>NXFQHRVNIOXGAQ-YCRREMRBSA-N</td>\n",
              "      <td>O=C1CN(/N=C/c2ccc([N+](=O)[O-])o2)C(=O)N1</td>\n",
              "      <td>-3.38</td>\n",
              "      <td>0.86</td>\n",
              "      <td>238.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4159</th>\n",
              "      <td>C1690</td>\n",
              "      <td>NXFQHRVNIOXGAQ-OQFOIZHKSA-N</td>\n",
              "      <td>O=C1CN(/N=C/c2ccc([N+](=O)[O-])o2)C(=O)N1</td>\n",
              "      <td>-3.24</td>\n",
              "      <td>0.86</td>\n",
              "      <td>238.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9020</th>\n",
              "      <td>C1565</td>\n",
              "      <td>CPNGPNLZQNNVQM-UHFFFAOYSA-N</td>\n",
              "      <td>c1cnc2ncncc2n1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.42</td>\n",
              "      <td>132.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9021</th>\n",
              "      <td>C1709</td>\n",
              "      <td>RKUNBYITZUJHSG-SPUOUPEWSA-N</td>\n",
              "      <td>c1cnc2ncncc2n1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.42</td>\n",
              "      <td>132.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7eb9938-92cc-46dd-9ce0-5a30140b5caf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7eb9938-92cc-46dd-9ce0-5a30140b5caf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7eb9938-92cc-46dd-9ce0-5a30140b5caf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48102b10-8023-4a90-8492-8e2eaf4f32fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48102b10-8023-4a90-8492-8e2eaf4f32fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48102b10-8023-4a90-8492-8e2eaf4f32fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"new_data_solubility[new_data_solubility['SMILES']\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Compound ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"C1565\",\n          \"C1690\",\n          \"C1698\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"InChIKey\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"CPNGPNLZQNNVQM-UHFFFAOYSA-N\",\n          \"NXFQHRVNIOXGAQ-OQFOIZHKSA-N\",\n          \"WUBBRNOQWQTFEX-UHFFFAOYSA-N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"CC(=O)Nc1nnc(S(N)(=O)=O)s1\",\n          \"CC(C)(C)NCC(O)COc1cccc2c1C[C@H](O)[C@H](O)C2\",\n          \"c1cnc2ncncc2n1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7225847679293544,\n        \"min\": -5.2800002,\n        \"max\": 0.02,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          -5.28,\n          -2.44,\n          -3.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.307322487863162,\n        \"min\": 0.4198,\n        \"max\": 3.7375,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.998,\n          1.0257,\n          0.4198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56.741089652112706,\n        \"min\": 132.123,\n        \"max\": 309.401,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          222.245,\n          309.401,\n          132.123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's drop rows that contain duplicate SMILES and keep the first structure:"
      ],
      "metadata": {
        "id": "QRSA4J581bCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_solubility_cleaned = new_data_solubility.drop_duplicates(subset=['SMILES'], keep='first')\n",
        "data_solubility_cleaned.shape\n",
        "data_solubility_cleaned.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jexwvrgv1lSe",
        "outputId": "7ddd7579-974a-4627-cb98-eb92f965b803"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Compound ID                     InChIKey  \\\n",
              "294       C1951  NZFNXWQNBYZDAQ-UHFFFAOYSA-N   \n",
              "295       C1952  CIMQMKORBAJNEC-UHFFFAOYSA-N   \n",
              "296       C1953  MOPIFNSMNXBREW-UHFFFAOYSA-N   \n",
              "297       C1954  CKHJPWQVLKHBIH-ZDSKVHJSSA-N   \n",
              "298       C1955  NAPSCFZYZVSQHF-UHFFFAOYSA-N   \n",
              "\n",
              "                                                SMILES  logS  logP     MW  \n",
              "294           CSc1ccc2c(c1)N(CCC1CCCCN1C)c1ccccc1S2.Cl -7.49  6.69 407.04  \n",
              "295  CC(=O)OCCN1CCN(CCCN2c3ccccc3Sc3ccc(C(F)(F)F)cc... -7.49  6.42 552.48  \n",
              "296                       CCCCCCCNc1c2ccccc2nc2ccccc12 -7.48  5.84 292.42  \n",
              "297  C/C(=C(\\CCOC(=O)C(C)C)SS/C(CCOC(=O)C(C)C)=C(/C... -7.47  7.12 702.89  \n",
              "298                            CCCCCCCCCCCCCCCCCCN(C)C -7.46  6.81 297.56  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b5227bf-9bfb-41c3-a67c-2e9c267ef0b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Compound ID</th>\n",
              "      <th>InChIKey</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>logS</th>\n",
              "      <th>logP</th>\n",
              "      <th>MW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>C1951</td>\n",
              "      <td>NZFNXWQNBYZDAQ-UHFFFAOYSA-N</td>\n",
              "      <td>CSc1ccc2c(c1)N(CCC1CCCCN1C)c1ccccc1S2.Cl</td>\n",
              "      <td>-7.49</td>\n",
              "      <td>6.69</td>\n",
              "      <td>407.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>C1952</td>\n",
              "      <td>CIMQMKORBAJNEC-UHFFFAOYSA-N</td>\n",
              "      <td>CC(=O)OCCN1CCN(CCCN2c3ccccc3Sc3ccc(C(F)(F)F)cc...</td>\n",
              "      <td>-7.49</td>\n",
              "      <td>6.42</td>\n",
              "      <td>552.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>C1953</td>\n",
              "      <td>MOPIFNSMNXBREW-UHFFFAOYSA-N</td>\n",
              "      <td>CCCCCCCNc1c2ccccc2nc2ccccc12</td>\n",
              "      <td>-7.48</td>\n",
              "      <td>5.84</td>\n",
              "      <td>292.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>C1954</td>\n",
              "      <td>CKHJPWQVLKHBIH-ZDSKVHJSSA-N</td>\n",
              "      <td>C/C(=C(\\CCOC(=O)C(C)C)SS/C(CCOC(=O)C(C)C)=C(/C...</td>\n",
              "      <td>-7.47</td>\n",
              "      <td>7.12</td>\n",
              "      <td>702.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>C1955</td>\n",
              "      <td>NAPSCFZYZVSQHF-UHFFFAOYSA-N</td>\n",
              "      <td>CCCCCCCCCCCCCCCCCCN(C)C</td>\n",
              "      <td>-7.46</td>\n",
              "      <td>6.81</td>\n",
              "      <td>297.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b5227bf-9bfb-41c3-a67c-2e9c267ef0b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b5227bf-9bfb-41c3-a67c-2e9c267ef0b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b5227bf-9bfb-41c3-a67c-2e9c267ef0b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb7c3b8e-171d-47ed-8216-2fa9829bef12\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb7c3b8e-171d-47ed-8216-2fa9829bef12')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb7c3b8e-171d-47ed-8216-2fa9829bef12 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_solubility_cleaned",
              "summary": "{\n  \"name\": \"data_solubility_cleaned\",\n  \"rows\": 9642,\n  \"fields\": [\n    {\n      \"column\": \"Compound ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9642,\n        \"samples\": [\n          \"C6375\",\n          \"C3694\",\n          \"C2683\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"InChIKey\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9640,\n        \"samples\": [\n          \"FLOSMHQXBMRNHR-DAXSKMNVSA-N\",\n          \"QEEBRPGZBVVINN-BMPKRDENSA-N\",\n          \"MAODNVTZUXOBNL-UHFFFAOYSA-N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9642,\n        \"samples\": [\n          \"CCS(=O)(=O)c1ccc(OCC(O)CN2CCN(c3ccccc3)CC2)cc1.Cl.Cl\",\n          \"CN(C)CCCC1(O)c2ccccc2COc2ccccc21\",\n          \"Cc1c(Cl)cccc1Nc1ccccc1C(=O)O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9327455739892947,\n        \"min\": -7.489053566,\n        \"max\": 1.58,\n        \"num_unique_values\": 8128,\n        \"samples\": [\n          -4.216891655,\n          -2.3699999,\n          -1.854877097\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1949721396671373,\n        \"min\": -10.9338,\n        \"max\": 20.8546,\n        \"num_unique_values\": 7953,\n        \"samples\": [\n          1.4262,\n          3.4089,\n          4.6099\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MW\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 131.36391462892325,\n        \"min\": 16.0425,\n        \"max\": 1583.57,\n        \"num_unique_values\": 6203,\n        \"samples\": [\n          275.775,\n          291.385,\n          304.795\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2.4 Filter training data\n",
        "\n",
        "Now that we have a dataset, let's prepapare a test stet containing 100 drug-like compounds (source: https://github.com/PatWalters/solubility)"
      ],
      "metadata": {
        "id": "HXSd0vY02KUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Nohalyan/Projetppchem/main/Data_Drug_Like_Solubility.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AsBNHVfErm_",
        "outputId": "ba6ae7fc-d0bb-4096-a77d-dfa0a7a37301"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-23 08:00:00--  https://raw.githubusercontent.com/Nohalyan/Projetppchem/main/Data_Drug_Like_Solubility.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5557 (5.4K) [text/plain]\n",
            "Saving to: ‘Data_Drug_Like_Solubility.csv’\n",
            "\n",
            "Data_Drug_Like_Solu 100%[===================>]   5.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-23 08:00:01 (34.0 MB/s) - ‘Data_Drug_Like_Solubility.csv’ saved [5557/5557]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Path object for the current directory, in our case /content/\n",
        "current_directory_dl = Path.cwd()\n",
        "print(\"Current Directory:\", current_directory.resolve())\n",
        "\n",
        "file_path_dl = current_directory / \"Data_Drug_Like_Solubility.csv\"\n",
        "\n",
        "# Reading the contents of the file and check that the file exists\n",
        "if file_path.exists():\n",
        "    with file_path.open(\"r\") as file:\n",
        "        content = file.read()\n",
        "#        print(content)\n",
        "else:\n",
        "    print(\"The file does not exist.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxxXu8QdElDW",
        "outputId": "3b14945b-3cec-41a3-c948-02d32a0fac37"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dl = pd.read_csv(\"/content/Data_Drug_Like_Solubility.csv\", delimiter=';')\n",
        "data_dl.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uz_TeGiFRWj",
        "outputId": "e2132583-9ae4-457c-e66d-db2147bc9767"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dl.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2U7jAFxBGt4i",
        "outputId": "83aa64b4-3181-4bf9-ba2a-11867c28eb50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Chemical name                                             SMILES  \\\n",
              "0    Acetanilide                                    O=C(Nc1ccccc1)C   \n",
              "1      Adenosine  c1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3...   \n",
              "2    Allopurinol                                c1c2c([nH]n1)ncnc2O   \n",
              "3   Trimethoprim                    COc1cc(cc(c1OC)OC)Cc2cnc(nc2N)N   \n",
              "4  Acetazolamide                         O=S(=O)(c1nnc(s1)NC(=O)C)N   \n",
              "\n",
              "   LogS exp (mol/L)  \n",
              "0             -1.40  \n",
              "1             -1.73  \n",
              "2             -2.26  \n",
              "3             -2.95  \n",
              "4             -2.44  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f7ee362-48d6-42ab-ad02-ba1ac351a43c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chemical name</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>LogS exp (mol/L)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Acetanilide</td>\n",
              "      <td>O=C(Nc1ccccc1)C</td>\n",
              "      <td>-1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adenosine</td>\n",
              "      <td>c1nc(c2c(n1)n(cn2)[C@H]3[C@@H]([C@@H]([C@H](O3...</td>\n",
              "      <td>-1.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allopurinol</td>\n",
              "      <td>c1c2c([nH]n1)ncnc2O</td>\n",
              "      <td>-2.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trimethoprim</td>\n",
              "      <td>COc1cc(cc(c1OC)OC)Cc2cnc(nc2N)N</td>\n",
              "      <td>-2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Acetazolamide</td>\n",
              "      <td>O=S(=O)(c1nnc(s1)NC(=O)C)N</td>\n",
              "      <td>-2.44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f7ee362-48d6-42ab-ad02-ba1ac351a43c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f7ee362-48d6-42ab-ad02-ba1ac351a43c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f7ee362-48d6-42ab-ad02-ba1ac351a43c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9a7fedf5-3446-4027-a3ba-7089339f0690\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a7fedf5-3446-4027-a3ba-7089339f0690')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9a7fedf5-3446-4027-a3ba-7089339f0690 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_dl",
              "summary": "{\n  \"name\": \"data_dl\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"Chemical name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Alclofenac\",\n          \"Pyrene\",\n          \"Linuron\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Clc1cc(ccc1OC\\\\C=C)CC(=O)O\",\n          \"c1cc2ccc3cccc4c3c2c(c1)cc4\",\n          \"Clc1ccc(NC(=O)N(OC)C)cc1Cl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LogS exp (mol/L)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.713461190843041,\n        \"min\": -8.8,\n        \"max\": 1.7,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          -3.61,\n          -2.97,\n          -5.46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate canonical Smiles\n",
        "canon_smiles = canonical_SMILES(data_dl.SMILES)\n",
        "\n",
        "# Replace SMILES column wit Canonical SMILES\n",
        "data_dl[\"SMILES\"] = canon_smiles\n",
        "\n",
        "# Create a list for duplicate smiles\n",
        "duplicate_data_dl_smiles = data_dl[data_dl['SMILES'].duplicated()]['SMILES'].values\n",
        "len(duplicate_data_dl_smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLHQ1dgrHL-m",
        "outputId": "43caa04d-43c3-44a9-9850-f6e5008bbac4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Molecules used in training and test of the model\n",
        "data_dl_SMILES = data_dl.SMILES.values\n",
        "\n",
        "# Filter molecules that are not present in the test set\n",
        "data_cleaned_final = data_solubility_cleaned[~data_solubility_cleaned['SMILES'].isin(data_dl_SMILES)]\n",
        "print(f'Compounds present in training set:{len(data_solubility_cleaned) - len(data_cleaned_final)}')\n",
        "data_cleaned_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akgVYCbtHqwk",
        "outputId": "ce726212-47e1-454d-9001-9549d3109d47"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compounds present in training set:93\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9549, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dl= data_dl[data_dl['LogS exp (mol/L)'].apply(lambda x: x > -7.5 and x < 1.7)]\n",
        "data_dl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jEoNO8CMLVqZ",
        "outputId": "e044596c-362f-4cdd-a7f9-5cf2d93535dc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Chemical name                                             SMILES  \\\n",
              "0       Acetanilide                                    CC(=O)Nc1ccccc1   \n",
              "1         Adenosine    Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O   \n",
              "2       Allopurinol                                  Oc1ncnc2[nH]ncc12   \n",
              "3      Trimethoprim                    COc1cc(Cc2cnc(N)nc2N)cc(OC)c1OC   \n",
              "4     Acetazolamide                         CC(=O)Nc1nnc(S(N)(=O)=O)s1   \n",
              "..              ...                                                ...   \n",
              "95    Sulfanilamide                              Nc1ccc(S(N)(=O)=O)cc1   \n",
              "96       Gliclazide            Cc1ccc(S(=O)(=O)NC(=O)NN2CC3CCCC3C2)cc1   \n",
              "97  Trihexyphenidyl                   OC(CCN1CCCCC1)(c1ccccc1)C1CCCCC1   \n",
              "98     Triphenylene                       c1ccc2c(c1)c1ccccc1c1ccccc21   \n",
              "99     Mifepristone  CC#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CCC4=C3[...   \n",
              "\n",
              "    LogS exp (mol/L)  \n",
              "0              -1.40  \n",
              "1              -1.73  \n",
              "2              -2.26  \n",
              "3              -2.95  \n",
              "4              -2.44  \n",
              "..               ...  \n",
              "95             -1.36  \n",
              "96             -4.29  \n",
              "97             -5.20  \n",
              "98             -6.73  \n",
              "99             -5.90  \n",
              "\n",
              "[98 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d06634ed-8b3c-4235-9ae4-535a925187f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chemical name</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>LogS exp (mol/L)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Acetanilide</td>\n",
              "      <td>CC(=O)Nc1ccccc1</td>\n",
              "      <td>-1.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adenosine</td>\n",
              "      <td>Nc1ncnc2c1ncn2[C@@H]1O[C@H](CO)[C@@H](O)[C@H]1O</td>\n",
              "      <td>-1.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Allopurinol</td>\n",
              "      <td>Oc1ncnc2[nH]ncc12</td>\n",
              "      <td>-2.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trimethoprim</td>\n",
              "      <td>COc1cc(Cc2cnc(N)nc2N)cc(OC)c1OC</td>\n",
              "      <td>-2.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Acetazolamide</td>\n",
              "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
              "      <td>-2.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Sulfanilamide</td>\n",
              "      <td>Nc1ccc(S(N)(=O)=O)cc1</td>\n",
              "      <td>-1.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Gliclazide</td>\n",
              "      <td>Cc1ccc(S(=O)(=O)NC(=O)NN2CC3CCCC3C2)cc1</td>\n",
              "      <td>-4.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Trihexyphenidyl</td>\n",
              "      <td>OC(CCN1CCCCC1)(c1ccccc1)C1CCCCC1</td>\n",
              "      <td>-5.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Triphenylene</td>\n",
              "      <td>c1ccc2c(c1)c1ccccc1c1ccccc21</td>\n",
              "      <td>-6.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Mifepristone</td>\n",
              "      <td>CC#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CCC4=C3[...</td>\n",
              "      <td>-5.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d06634ed-8b3c-4235-9ae4-535a925187f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d06634ed-8b3c-4235-9ae4-535a925187f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d06634ed-8b3c-4235-9ae4-535a925187f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-575a45c2-30d4-4c64-8d89-745fa702a991\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-575a45c2-30d4-4c64-8d89-745fa702a991')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-575a45c2-30d4-4c64-8d89-745fa702a991 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_dl",
              "summary": "{\n  \"name\": \"data_dl\",\n  \"rows\": 98,\n  \"fields\": [\n    {\n      \"column\": \"Chemical name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"Thalidomide\",\n          \"Papaverine\",\n          \"Gliclazide\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"O=C1CCC(N2C(=O)c3ccccc3C2=O)C(=O)N1\",\n          \"COc1ccc(Cc2nccc3cc(OC)c(OC)cc23)cc1OC\",\n          \"Cc1ccc(S(=O)(=O)NC(=O)NN2CC3CCCC3C2)cc1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LogS exp (mol/L)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5564845320349727,\n        \"min\": -6.75,\n        \"max\": 0.48,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          -1.98,\n          -4.15,\n          -2.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Calculation of RDkit Molecular Descriptors, which are molecular features"
      ],
      "metadata": {
        "id": "IwdeeEJMLtxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RDkit_descriptors(smiles):\n",
        "    mols = [Chem.MolFromSmiles(i) for i in smiles]\n",
        "    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0]\n",
        "                                    for x in Descriptors._descList])\n",
        "    desc_names = calc.GetDescriptorNames()\n",
        "\n",
        "    Mol_descriptors =[]\n",
        "    for mol in tqdm(mols):\n",
        "        # add hydrogens to molecules\n",
        "        mol=Chem.AddHs(mol)\n",
        "        # Calculate all 200 descriptors for each molecule\n",
        "        descriptors = calc.CalcDescriptors(mol)\n",
        "        Mol_descriptors.append(descriptors)\n",
        "    return Mol_descriptors,desc_names\n",
        "\n",
        "# Function call\n",
        "Mol_descriptors,desc_names = RDkit_descriptors(data_cleaned_final['SMILES'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiwjxW8iL39L",
        "outputId": "3faffbfa-243f-48e5-8acf-113bf7b6f1ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 99%|█████████▉| 9495/9549 [12:10<00:02, 24.59it/s][08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:20] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 99%|█████████▉| 9498/9549 [12:11<00:02, 25.39it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 99%|█████████▉| 9501/9549 [12:11<00:01, 25.07it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9505/9549 [12:11<00:01, 27.81it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9508/9549 [12:11<00:01, 28.29it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9511/9549 [12:11<00:01, 28.71it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9514/9549 [12:11<00:01, 29.04it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9517/9549 [12:11<00:01, 28.57it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9520/9549 [12:11<00:01, 28.95it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9523/9549 [12:11<00:00, 28.60it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9526/9549 [12:11<00:00, 27.68it/s][08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9529/9549 [12:12<00:00, 27.45it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9532/9549 [12:12<00:00, 21.88it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9535/9549 [12:12<00:00, 18.33it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9538/9549 [12:12<00:00, 18.94it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9542/9549 [12:12<00:00, 21.76it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|█████████▉| 9545/9549 [12:12<00:00, 23.20it/s][08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[08:17:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|██████████| 9549/9549 [12:13<00:00, 13.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_descriptors = pd.DataFrame(Mol_descriptors, columns=desc_names)\n",
        "df_descriptors.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "1v7UGPE6OLKA",
        "outputId": "da146307-29ed-4634-97ec-a4e80d431777"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  qed  \\\n",
              "0               9.25            9.25               0.05           -4.68 0.55   \n",
              "1              14.36           14.36               0.00           -5.72 0.41   \n",
              "2               8.72            8.72               0.55           -4.55 0.44   \n",
              "3              13.83           13.83               0.86           -5.29 0.12   \n",
              "4               8.30            8.30               1.26           -5.38 0.27   \n",
              "\n",
              "    SPS  MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  ...  \\\n",
              "0 46.96 407.05          379.83      406.13                  140  ...   \n",
              "1 36.20 552.49          522.25      551.14                  194  ...   \n",
              "2 31.45 292.43          268.23      292.19                  114  ...   \n",
              "3 30.50 702.90          656.54      702.30                  262  ...   \n",
              "4 55.19 297.57          254.23      297.34                  128  ...   \n",
              "\n",
              "   fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  fr_tetrazole  \\\n",
              "0           1             0           0                  0             0   \n",
              "1           0             0           0                  0             0   \n",
              "2           0             0           0                  0             0   \n",
              "3           0             0           0                  0             0   \n",
              "4           0             0           0                  0             0   \n",
              "\n",
              "   fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  fr_urea  \n",
              "0            0            0             0                 0        0  \n",
              "1            0            0             0                 0        0  \n",
              "2            0            0             0                 0        0  \n",
              "3            0            0             0                 0        0  \n",
              "4            0            0             0                 0        0  \n",
              "\n",
              "[5 rows x 210 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6571d95-9b5d-4892-884f-5e228c550e24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MaxAbsEStateIndex</th>\n",
              "      <th>MaxEStateIndex</th>\n",
              "      <th>MinAbsEStateIndex</th>\n",
              "      <th>MinEStateIndex</th>\n",
              "      <th>qed</th>\n",
              "      <th>SPS</th>\n",
              "      <th>MolWt</th>\n",
              "      <th>HeavyAtomMolWt</th>\n",
              "      <th>ExactMolWt</th>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <th>...</th>\n",
              "      <th>fr_sulfide</th>\n",
              "      <th>fr_sulfonamd</th>\n",
              "      <th>fr_sulfone</th>\n",
              "      <th>fr_term_acetylene</th>\n",
              "      <th>fr_tetrazole</th>\n",
              "      <th>fr_thiazole</th>\n",
              "      <th>fr_thiocyan</th>\n",
              "      <th>fr_thiophene</th>\n",
              "      <th>fr_unbrch_alkane</th>\n",
              "      <th>fr_urea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.25</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.05</td>\n",
              "      <td>-4.68</td>\n",
              "      <td>0.55</td>\n",
              "      <td>46.96</td>\n",
              "      <td>407.05</td>\n",
              "      <td>379.83</td>\n",
              "      <td>406.13</td>\n",
              "      <td>140</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.36</td>\n",
              "      <td>14.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-5.72</td>\n",
              "      <td>0.41</td>\n",
              "      <td>36.20</td>\n",
              "      <td>552.49</td>\n",
              "      <td>522.25</td>\n",
              "      <td>551.14</td>\n",
              "      <td>194</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.72</td>\n",
              "      <td>8.72</td>\n",
              "      <td>0.55</td>\n",
              "      <td>-4.55</td>\n",
              "      <td>0.44</td>\n",
              "      <td>31.45</td>\n",
              "      <td>292.43</td>\n",
              "      <td>268.23</td>\n",
              "      <td>292.19</td>\n",
              "      <td>114</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.83</td>\n",
              "      <td>13.83</td>\n",
              "      <td>0.86</td>\n",
              "      <td>-5.29</td>\n",
              "      <td>0.12</td>\n",
              "      <td>30.50</td>\n",
              "      <td>702.90</td>\n",
              "      <td>656.54</td>\n",
              "      <td>702.30</td>\n",
              "      <td>262</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.30</td>\n",
              "      <td>8.30</td>\n",
              "      <td>1.26</td>\n",
              "      <td>-5.38</td>\n",
              "      <td>0.27</td>\n",
              "      <td>55.19</td>\n",
              "      <td>297.57</td>\n",
              "      <td>254.23</td>\n",
              "      <td>297.34</td>\n",
              "      <td>128</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 210 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6571d95-9b5d-4892-884f-5e228c550e24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6571d95-9b5d-4892-884f-5e228c550e24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6571d95-9b5d-4892-884f-5e228c550e24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d04adb81-25fa-4fe0-8963-f6c901abfa48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d04adb81-25fa-4fe0-8963-f6c901abfa48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d04adb81-25fa-4fe0-8963-f6c901abfa48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_descriptors"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_descriptors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLerraWYQhCX",
        "outputId": "64daef64-530e-4df1-819f-88d152410ac3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9549, 210)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Split the chemicals for training and validation set"
      ],
      "metadata": {
        "id": "KZFGKSecQqsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(df_descriptors, data_cleaned_final.logS, test_size=0.1,random_state=42)\n",
        "\n",
        "#Standardization of the features\n",
        "\n",
        "custom_scaler = StandardScaler()\n",
        "custom_scaler.fit(x_train)\n",
        "x_train_scaled = custom_scaler.transform(x_train)\n",
        "x_valid_scaled = custom_scaler.transform(x_valid)"
      ],
      "metadata": {
        "id": "xtfxtv4bQ1JW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Select Machine Learning Models\n",
        "\n",
        "Let's selct the best ML models for that. To do that, we will use the lazypredict librarie, in particular the LazyRegressor function to test 42 ML models:"
      ],
      "metadata": {
        "id": "ObN4zyriRhtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lregs = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None,random_state=42)\n",
        "models, prediction_tests = lregs.fit(x_train_scaled, x_valid_scaled, y_train, y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVj91hWoRkr-",
        "outputId": "65c8b1ab-bb8f-44e4-ce8e-99230ab2930f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 41/42 [05:44<00:04,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20819\n",
            "[LightGBM] [Info] Number of data points in the train set: 8594, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.762630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [05:46<00:00,  8.25s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The top three models\n",
        "prediction_tests[:5]"
      ],
      "metadata": {
        "id": "djOzUCFpWF-z",
        "outputId": "72499262-abb7-4d09-c173-61f18c6492a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
              "Model                                                                         \n",
              "HistGradientBoostingRegressor                0.82       0.86  0.74       15.19\n",
              "LGBMRegressor                                0.81       0.85  0.75        2.12\n",
              "ExtraTreesRegressor                          0.80       0.84  0.77       28.04\n",
              "XGBRegressor                                 0.79       0.84  0.78        3.73\n",
              "RandomForestRegressor                        0.79       0.84  0.78       65.07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4389bb38-9eac-4813-a95e-21feeac7142e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Adjusted R-Squared</th>\n",
              "      <th>R-Squared</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>HistGradientBoostingRegressor</th>\n",
              "      <td>0.82</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.74</td>\n",
              "      <td>15.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMRegressor</th>\n",
              "      <td>0.81</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesRegressor</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.77</td>\n",
              "      <td>28.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBRegressor</th>\n",
              "      <td>0.79</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.78</td>\n",
              "      <td>3.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestRegressor</th>\n",
              "      <td>0.79</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.78</td>\n",
              "      <td>65.07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4389bb38-9eac-4813-a95e-21feeac7142e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4389bb38-9eac-4813-a95e-21feeac7142e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4389bb38-9eac-4813-a95e-21feeac7142e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bea528c0-1e1b-4ff4-ad7f-39f8930a8620\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bea528c0-1e1b-4ff4-ad7f-39f8930a8620')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bea528c0-1e1b-4ff4-ad7f-39f8930a8620 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"prediction_tests[:5]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"LGBMRegressor\",\n          \"RandomForestRegressor\",\n          \"ExtraTreesRegressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adjusted R-Squared\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010881901676083874,\n        \"min\": 0.7914622054946432,\n        \"max\": 0.8151125232111568,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8112350576750624,\n          0.7914622054946432,\n          0.7989427417077389\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R-Squared\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008486514514681758,\n        \"min\": 0.8373667514549419,\n        \"max\": 0.8558110243910908,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8527870890044512,\n          0.8373667514549419,\n          0.8432006287532052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021062835133446055,\n        \"min\": 0.7383987708763431,\n        \"max\": 0.784204997123054,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7461014554341195,\n          0.784204997123054,\n          0.7700112943224983\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time Taken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.804900971996947,\n        \"min\": 2.1160218715667725,\n        \"max\": 65.06857466697693,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.1160218715667725,\n          65.06857466697693,\n          28.038766384124756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Fine-tuning of LGBMRegressor\n",
        "\n",
        "We decided to take the LGBMRegressor model because the results generated by this model are comparable to the ExtraTreesRegressor model, but takes a lot less time than the extra-trees model.Let's performs a grid search using GridSearchCV from scikit-learn to find the best hyperparameters for a LightGBM regressor:"
      ],
      "metadata": {
        "id": "WHz1RVk6WlW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'max_depth' : list(range(2, 32, 8)),\n",
        "          'n_estimators' : list(range(1, 1000, 100)),\n",
        "          'learning_rate' : list(np.arange(0.01, 1.02, 0.25))}\n",
        "\n",
        "grid_search = GridSearchCV(LGBMRegressor(random_state = 42),\n",
        "                            param_grid=params, cv=5, verbose=1)\n",
        "\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "print(\"Optimized parameters for a LightGBM regressor can be: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "4C5cOJ4hXG3M",
        "outputId": "4eb4ecbf-a2ad-4908-be78-378e7be94f1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030612 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020808 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021276 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011303 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023466 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020889 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022539 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021583 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022497 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020175 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021347 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021402 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023955 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023811 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032669 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022625 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020826 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022288 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021238 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031283 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020392 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026192 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010883 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020874 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020300 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025118 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021654 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028448 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020629 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022427 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036325 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020835 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024806 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031058 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030377 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020849 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021269 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037242 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020609 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020858 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014340 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023293 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030808 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031388 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031442 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022181 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019972 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026485 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024592 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020410 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020814 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021317 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020980 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020649 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020956 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021134 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021510 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021055 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021042 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020571 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020997 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021482 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020417 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021162 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021468 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022105 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020731 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024850 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030475 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022470 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021075 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020966 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020892 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020464 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021210 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021390 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021114 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021326 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023479 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021369 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020386 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021243 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024968 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025313 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021051 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020850 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022391 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021195 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030132 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021247 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020659 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032787 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020804 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020517 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020941 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021376 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022261 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033137 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020974 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031731 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020884 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029839 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023297 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020597 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020984 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021165 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020864 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022627 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021924 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021641 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023028 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036267 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021048 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028434 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020199 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026999 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026923 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020326 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026998 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029992 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021693 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021390 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023639 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020931 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020862 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021178 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021383 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033874 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029458 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021668 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021103 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023503 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020385 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021170 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021399 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031321 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021238 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021253 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020258 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040463 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020733 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021313 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020569 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021618 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033468 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021219 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020492 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021456 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035884 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020147 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021296 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021024 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021023 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022733 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020806 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022556 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021564 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020508 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024824 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028579 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029259 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020951 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020746 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020719 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022675 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033518 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020720 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021305 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030991 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020373 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032018 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020704 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020498 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024001 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021174 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022045 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020391 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022663 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023104 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033999 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021471 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021961 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025936 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021603 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021304 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020691 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027559 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021113 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021947 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021059 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024237 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020490 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021041 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021129 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033574 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026897 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026574 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023204 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024049 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021097 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030393 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020934 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027729 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020217 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034867 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021001 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022095 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021185 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021214 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021080 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020557 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029871 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021102 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020899 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022256 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020687 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021428 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020738 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022651 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021016 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028805 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021373 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022501 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020411 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033149 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021064 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020607 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035450 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034024 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021082 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020976 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021428 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031415 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023519 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023328 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024488 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025161 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021084 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035788 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021156 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021050 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020296 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020990 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022903 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020719 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022696 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020949 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015863 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021001 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021843 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020208 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021356 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020803 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022721 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020924 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021140 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028278 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021017 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021351 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022361 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022429 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021644 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020495 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021686 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021226 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021053 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020905 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020840 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20852\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.756593\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20919\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.739100\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020555 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20805\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.770454\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034942 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20926\n",
            "[LightGBM] [Info] Number of data points in the train set: 6875, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.786975\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20892\n",
            "[LightGBM] [Info] Number of data points in the train set: 6876, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.760028\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027389 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 21196\n",
            "[LightGBM] [Info] Number of data points in the train set: 8594, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.762630\n",
            "The best parameters for a LightGBM regressor are:  {'learning_rate': 0.01, 'max_depth': 26, 'n_estimators': 901}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtained:\n",
        "* learning_rate: 0.01\n",
        "* max_depth: 26\n",
        "* n_estmitors: 901\n",
        "\n",
        "Let's optimize again with new ranges for liste max_depth, n_estmitors and learning_rate to obtain even better parameters:\n"
      ],
      "metadata": {
        "id": "ELET-iZOcmPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_bst = {\"max_depth\" : list(range(20, 36, 4)),\n",
        "         \"n_estimators\" : list(range(850, 1200, 50)),\n",
        "         \"learning_rate\" : list(np.arange(0.01, 0.05, 0.01))}\n",
        "\n",
        "grid_search_bst = GridSearchCV(LGBMRegressor(random_state = 42),\n",
        "                                  param_grid=params_bst, cv=3, verbose=1)\n",
        "\n",
        "grid_search_bst.fit(x_train, y_train)\n",
        "print(\"The best parameters are: \", grid_search_bst.best_params_)"
      ],
      "metadata": {
        "id": "Kwe8dQKHNTzt",
        "outputId": "656f3d18-1360-4188-995e-9040466d5f40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 112 candidates, totalling 336 fits\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017104 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031667 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015252 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024882 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032271 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012781 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030737 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027182 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017606 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035389 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017871 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019679 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033827 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018101 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017148 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016562 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017849 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020263 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017821 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010801 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028112 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017863 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017251 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021680 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029602 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027925 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012404 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033522 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027062 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017049 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017567 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017444 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018084 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018489 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031279 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017438 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016923 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018780 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019646 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016784 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017236 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017033 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009050 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016795 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017633 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017081 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016795 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019002 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017312 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016727 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025506 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017145 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016960 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017541 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017642 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016702 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008893 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018025 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016305 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018908 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017254 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016492 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019020 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017026 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016923 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018105 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016824 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017903 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017657 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017713 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016671 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027987 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017652 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025530 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018360 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027842 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019810 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017003 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017156 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018037 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033326 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017223 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016859 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018111 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020258 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016578 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018448 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027744 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008951 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017403 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018019 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020374 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017954 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017658 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017956 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017755 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017089 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016586 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018001 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017499 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017608 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017156 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016766 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036336 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018032 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016791 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009426 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018161 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016669 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018819 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017447 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017734 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026954 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027898 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017926 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017488 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017949 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017511 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017717 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017145 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035638 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027933 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017097 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020781 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019651 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018145 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025570 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017311 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016629 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025197 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033204 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016800 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017605 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017272 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016481 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017886 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022352 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016754 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018739 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017770 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016684 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014919 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027261 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021298 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019534 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018945 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020564 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032695 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017503 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017427 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016901 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017917 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017046 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019513 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019297 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017988 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017563 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017195 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016348 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017023 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017651 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017724 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017201 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023632 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017334 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018416 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030939 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017745 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016807 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018403 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017951 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016842 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017813 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018005 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017063 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017858 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017505 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016735 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031342 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017478 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017142 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017877 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017259 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016724 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017887 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017133 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029342 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017563 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016686 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017998 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017762 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017281 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017266 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016659 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017349 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017555 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029981 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016373 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031073 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016837 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017689 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017646 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016833 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017784 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027979 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037289 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017821 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017325 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016857 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018249 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031406 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031195 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027219 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017120 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017598 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019479 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016712 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018524 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021384 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026546 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017939 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019221 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018550 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017492 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017859 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017869 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018693 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017139 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016677 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018239 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008886 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030966 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016496 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019494 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017480 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017759 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017796 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017065 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020407 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020631 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017189 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019360 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017999 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017375 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023289 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017129 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017893 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019164 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016777 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017878 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018015 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017451 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016812 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037904 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030380 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016683 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017024 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021798 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017849 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017108 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017988 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027635 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017855 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019399 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017755 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019167 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012893 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016973 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031165 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017278 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016437 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017957 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021043 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016769 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021024 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017116 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016888 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018046 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017215 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016995 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20548\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 187\n",
            "[LightGBM] [Info] Start training from score -2.739573\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021449 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20589\n",
            "[LightGBM] [Info] Number of data points in the train set: 5729, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.771144\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017274 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20514\n",
            "[LightGBM] [Info] Number of data points in the train set: 5730, number of used features: 188\n",
            "[LightGBM] [Info] Start training from score -2.777171\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026787 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 21196\n",
            "[LightGBM] [Info] Number of data points in the train set: 8594, number of used features: 196\n",
            "[LightGBM] [Info] Start training from score -2.762630\n",
            "The best parameters are:  {'learning_rate': 0.04, 'max_depth': 24, 'n_estimators': 1150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. LGBMRegressor model for training and test data\n",
        "Let's test our model ont the training and test set with the best parameters found with the fine tunning:\n",
        "* learning_rate: 0.04\n",
        "* max_depth: 24\n",
        "* n_estmitors: 1150\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dfuMUiEYAu01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LGBMRegressor(n_estimators = 1150,\n",
        "                      max_depth = 24,\n",
        "                      learning_rate = 0.04,\n",
        "                      random_state= 42)\n",
        "\n",
        "model.fit(x_train_scaled,y_train)\n",
        "y_preds = model.predict(x_valid_scaled)"
      ],
      "metadata": {
        "id": "lV5YnDz4BOhz",
        "outputId": "bf94c0ad-b7c3-43be-d405-8a9ddf23e307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042274 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 20899\n",
            "[LightGBM] [Info] Number of data points in the train set: 8594, number of used features: 195\n",
            "[LightGBM] [Info] Start training from score -2.762630\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A plotting function\n",
        "def plot_data(actual, predicted, title):\n",
        "\n",
        "# model performance using RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# R^2 (coefficient of determination) :\n",
        "    R2 =r2_score(actual, predicted)\n",
        "    plt.figure(figsize=(8,6))\n",
        "\n",
        "# Plot the figure\n",
        "    sn.regplot(x=predicted , y=actual,line_kws={\"lw\":2,\n",
        "                                                \"ls\":\"--\",\n",
        "                                                \"color\":\"red\",\n",
        "                                                \"alpha\":0.7})\n",
        "    plt.title(title, color=\"red\")\n",
        "    plt.xlabel(\"Predicted logS(mol/L)\",\n",
        "               color=\"blue\")\n",
        "    plt.xlim(-8,1)\n",
        "    plt.ylabel(\"Experimental logS(mol/L)\",\n",
        "               color =\"blue\")\n",
        "\n",
        "\n",
        "    plt.grid(alpha=0.3)\n",
        "    R2 = mpatches.Patch(label=\"R2={:04.2f}\".format(R2))\n",
        "    rmse = mpatches.Patch(label=\"RMSE={:04.2f}\".format(rmse))\n",
        "    plt.legend(handles=[R2, rmse])"
      ],
      "metadata": {
        "id": "vYAhA4_1ChMy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the predicted logS of the validation set and see if our model works:"
      ],
      "metadata": {
        "id": "oLXafM4bEpJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sn.set_theme(style=\"whitegrid\")\n",
        "plot_data(y_valid,y_preds,\"Validation data\")"
      ],
      "metadata": {
        "id": "xtO2vsUUEnMh",
        "outputId": "4092f0b4-e6ec-4f8b-9e10-76047ff5d016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate molecular descriptors for the test data or 98 compounds\n",
        "\n",
        "Mol_descriptors_test , desc_names_test = RDkit_descriptors(data_dl[\"SMILES\"])\n",
        "data_dl_descriptors = pd.DataFrame(Mol_descriptors_test,columns=desc_names_test)\n",
        "\n",
        "# Standard scaler - transform\n",
        "x_scaled_test = custom_scaler.transform(data_dl_descriptors)\n",
        "\n",
        "# Predict solubility of the test data\n",
        "y_test_preds = model.predict(x_scaled_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "PzzUsNv0En7a",
        "outputId": "5709b528-743d-476d-8799-591189835c2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 49%|████▉     | 48/98 [00:02<00:02, 19.92it/s][13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 51%|█████     | 50/98 [00:02<00:02, 18.90it/s][13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 54%|█████▍    | 53/98 [00:02<00:02, 20.07it/s][13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 56%|█████▌    | 55/98 [00:02<00:02, 18.53it/s][13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:21] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 59%|█████▉    | 58/98 [00:02<00:02, 18.82it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 62%|██████▏   | 61/98 [00:03<00:01, 19.46it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 65%|██████▌   | 64/98 [00:03<00:01, 20.92it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 68%|██████▊   | 67/98 [00:03<00:01, 21.18it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 71%|███████▏  | 70/98 [00:03<00:01, 20.74it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 74%|███████▍  | 73/98 [00:03<00:01, 19.23it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 78%|███████▊  | 76/98 [00:03<00:01, 20.13it/s][13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:22] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 81%|████████  | 79/98 [00:03<00:00, 19.50it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 83%|████████▎ | 81/98 [00:04<00:00, 19.12it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 86%|████████▌ | 84/98 [00:04<00:00, 19.67it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 88%|████████▊ | 86/98 [00:04<00:00, 19.60it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 90%|████████▉ | 88/98 [00:04<00:00, 19.18it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 92%|█████████▏| 90/98 [00:04<00:00, 19.28it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 94%|█████████▍| 92/98 [00:04<00:00, 19.02it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 97%|█████████▋| 95/98 [00:04<00:00, 19.41it/s][13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:23] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            " 99%|█████████▉| 97/98 [00:04<00:00, 18.07it/s][13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "[13:24:24] \n",
            "\n",
            "****\n",
            "Pre-condition Violation\n",
            "bad result vector size\n",
            "Violation occurred on line 40 in file /project/build/temp.linux-x86_64-cpython-310/rdkit/Code/GraphMol/Descriptors/Crippen.cpp\n",
            "Failed Expression: logpContribs.size() == mol.getNumAtoms() && mrContribs.size() == mol.getNumAtoms()\n",
            "----------\n",
            "Stacktrace:\n",
            "----------\n",
            "****\n",
            "\n",
            "100%|██████████| 98/98 [00:05<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting testing set\n",
        "sn.set_theme(style=\"whitegrid\")\n",
        "plot_data(data_dl[\"LogS exp (mol/L)\"], y_test_preds,\n",
        "           \"Test data: Drug-like Molecules\")"
      ],
      "metadata": {
        "id": "hf_U34X3eEju",
        "outputId": "dc126d16-e1bb-4ba6-899e-426bf56eac0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Saving of the trained model and standard scaler"
      ],
      "metadata": {
        "id": "dG-nNTVGJGQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"model_WSP.pkl\",\"wb\") as f:\n",
        "    pickle.dump(model,f)\n",
        "\n",
        "with open(\"scaler_WSP.pkl\",\"wb\") as f:\n",
        "    pickle.dump(custom_scaler,f)"
      ],
      "metadata": {
        "id": "LBUk2hL7JdwC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "id": "owJwsueKIuXH",
        "outputId": "20159f6a-db91-4174-d82e-9ce40bdccbfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data_Drug_Like_Solubility.csv  model.pkl      \u001b[0m\u001b[01;34msample_data\u001b[0m/  scaler_WSP.pkl\n",
            "Data_Solubility.csv            model_WSP.pkl  scaler.pkl\n"
          ]
        }
      ]
    }
  ]
}